{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "rx8qOic1kGCi"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahcoderepo/NLP/blob/main/NLP-Assignment/RAH_NLP_Assignment_2_prep_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "vpF_2bK2I3_G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CAI2300C - Fall 2024 - Professor Lee\n",
        "NLP Assignment 2\n",
        "Student: Roberto A Hernandez / 4000159004\n",
        "\n",
        "GitHub Path (Use it to Save Colab File to GitHub):\n",
        "RAH-Assignments/RAH_NLP_Assignment_2_prep_workshop.ipynb\n",
        "\n",
        "GitHub Permalink:\n",
        "https://github.com/rahcoderepo/NLP/blob/b6d8f96204f9ac8eb7957980c1bf34034504f651/NLP-Assignment/RAH_NLP_Assignment_2_prep_workshop.ipynb\n"
      ],
      "metadata": {
        "id": "-ubZslfFJEX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 000 - Define Processing Parameters\n",
        "         Cells:\n",
        "         1 - Define Function to Check for User defined parameters\n",
        "         \n",
        "\n"
      ],
      "metadata": {
        "id": "FIL49MOtlHGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title All in One Parameters List\n",
        "# Note: not really needed but added here anyways to make it easier for me to review all parameters in one place\n",
        "Load_DataSet_Option = None # DataSet to load\n"
      ],
      "metadata": {
        "id": "HnEAFM7hVmUu"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Function To Request Parameters from the user\n",
        "\n",
        "# Parameter Initialization Cell\n",
        "def get_user_input(prompt, expected_type, default_value=None):\n",
        "    \"\"\"\n",
        "    Prompt user for input, validate it, and return the value.\n",
        "    If invalid or skipped, return default_value.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        user_input = input(prompt)\n",
        "        if user_input.strip() == \"\":\n",
        "            return default_value  # No input, return default_value\n",
        "        # Try to cast to the expected type\n",
        "        value = expected_type(user_input)\n",
        "        return value\n",
        "    except ValueError:\n",
        "        return default_value  # Invalid input, return default_value\n",
        "\n",
        "# Parameter Definitions\n",
        "Load_DataSet_Option = get_user_input(\"Select DataSet To Load (1 or 2)\", int)\n",
        "\n",
        "\n",
        "# Print out the parameters for verification\n",
        "print(\"\\n--- Parameter Values ---\")\n",
        "print(f\"DataSet To Load: {Load_DataSet_Option}\")\n",
        "\n",
        "print(\"------------------------\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIrzpslWSpv8",
        "outputId": "ce55e3f3-f6af-44f6-b078-8cde425299a7"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select DataSet To Load (1 or 2)2\n",
            "\n",
            "--- Parameter Values ---\n",
            "DataSet To Load: 2\n",
            "------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Function to Check for User defined parameters\n",
        "def set_parameter_value(var_name, default_value):\n",
        "    \"\"\"\n",
        "    Sets a variable with a given name and default value.\n",
        "    If the variable exists and its value is None, the default value is assigned.\n",
        "    If the variable exists and is not None, it remains unchanged.\n",
        "    \"\"\"\n",
        "    global_vars = globals() # Access the global symbol table\n",
        "    # Check if the variable exists\n",
        "    if var_name in global_vars:\n",
        "        if global_vars[var_name] is None:  # If the value is NULL/None\n",
        "            global_vars[var_name] = default_value\n",
        "    else:\n",
        "        # If the variable doesn't exist, create it with the default value\n",
        "        global_vars[var_name] = default_value\n"
      ],
      "metadata": {
        "id": "y1kWWHe1RZTi"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Loading huggingface token\n",
        "# token name: CAI2300C-20241108-Class\n",
        "# token value: next line for easy copy (copy and paste below when prompted)\n",
        "#               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\n",
        "# Note: having the token value defeats the purpose of the getpass, but it is added because in\n",
        "#       real life situations that is how you protect your token and you will not include the\n",
        "#       token value a spart of your code\n",
        "\n",
        "from getpass import getpass\n",
        "HUGGINGFACE_TOKEN = getpass(\"Enter your Hugging Face token:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjfNuLYylQrG",
        "outputId": "58fb6132-a4b8-462a-a5c8-3947fdefe0c9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Hugging Face token:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 001 - Code Block\n",
        "        \n",
        "        Cells:\n",
        "        1 - Loading Libraries / Importing Packages\n",
        "        2 - Import the Libraries\n",
        "        3 - Loading the Dataset\n",
        "        4 - Inspecting the DataSet - Relevant Information\n",
        "        5 - Text Cleaning and Tokenization - Define Functions\n",
        "        6 - Text Cleaning and Tokenization - Processing\n",
        "        7 - Converting Labels to Numeric Format\n",
        "        8 - Explore X and y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kriwdKg3kuyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Loading Libraries / Importing Packages\n",
        "# List of required libraries\n",
        "libraries = {\n",
        "    \"tensorflow\": \"tensorflow\",\n",
        "    \"numpy\": \"numpy\",\n",
        "    \"pandas\": \"pandas\",\n",
        "    \"matplotlib\": \"matplotlib\",\n",
        "    \"sklearn\": \"scikit-learn\",\n",
        "    \"transformers4450\": \"transformers>=4.45.0\",\n",
        "    \"pillow\": \"pillow\",\n",
        "    \"Pytorch\": \"torch torchvision torchaudio\"\n",
        "}\n",
        "\n",
        "# Install only missing libraries\n",
        "for lib_name, package_name in libraries.items():\n",
        "    try:\n",
        "        __import__(lib_name)\n",
        "        print(f\"{lib_name} is already installed.\")\n",
        "    except ImportError:\n",
        "        print(f\"{lib_name} is not installed. Installing now...\")\n",
        "        !pip install {package_name}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTiu7d_PLVDH",
        "outputId": "d8dfdb16-7cd9-4aa8-9f03-2d017d91b273"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow is already installed.\n",
            "numpy is already installed.\n",
            "pandas is already installed.\n",
            "matplotlib is already installed.\n",
            "sklearn is already installed.\n",
            "transformers4450 is not installed. Installing now...\n",
            "pillow is not installed. Installing now...\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Pytorch is not installed. Installing now...\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import the Libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from datetime import datetime\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "DC2FJ36bLfh2"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Loading the Dataset\n",
        "# (Must define which dataset to load, default is dataset #1 which is RAH reduced size IMDb movie reviews dataset from Kaggle saved to RAH GitHub)\n",
        "\n",
        "#    Combines multiple CSV files into a single DataFrame.\n",
        "def combine_csv_files(file_dict):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        file_dict (dict): A dictionary where keys are file order (integers) and values are CSV URLs.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A single DataFrame combining all the CSV files.\n",
        "    \"\"\"\n",
        "    data_frames = []  # List to hold individual DataFrames\n",
        "\n",
        "    # Iterate through the dictionary in the order of keys\n",
        "    for file_order in sorted(file_dict.keys()):\n",
        "        url = file_dict[file_order]\n",
        "        print(f\"Loading CSV file for key {file_order}: {url}\")\n",
        "        df = pd.read_csv(url)  # Load the CSV file\n",
        "        data_frames.append(df)  # Append the DataFrame to the list\n",
        "\n",
        "    # Combine all DataFrames into one\n",
        "    combined_df = pd.concat(data_frames, ignore_index=True)  # Combine DataFrames\n",
        "    print(f\"Combined DataFrame has {len(combined_df)} records.\")\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "\n",
        "# A DataSet will be loaded using the following variables: # Load_DataSet_Option, main_data_field and senti_data_field\n",
        "# main_data_field and senti_data_field variables allows us to reuse the same code for different datasets by storing\n",
        "# the name of the relevant fields in the variables.\n",
        "\n",
        "# Select the file_dict value for the dataset you are running\n",
        "set_parameter_value(\"Load_DataSet_Option\", 1) #Check for Parameters User Manual Entry\n",
        "\n",
        "if Load_DataSet_Option == 1: # Default value (reduced size IMDB - RAH GitHub)\n",
        "    #Only one URL (Small Set to Test)\n",
        "    file_dict = {\n",
        "        1: \"https://raw.githubusercontent.com/rahcoderepo/NLP/refs/heads/main/DataSets/IMDB%20Dataset-GitHub-Ready-Less-Record.csv\"\n",
        "    }\n",
        "    main_data_field = \"review\" # This is the field name where the data to be trained on is found\n",
        "    senti_data_field = \"sentiment\" # This is the field name where the labels are found (Sentiment: Positive or Negative)\n",
        "\n",
        "elif Load_DataSet_Option == 2:\n",
        "    # Multiple URL (All 3 files that combined contains all data in IMDB Dataset)\n",
        "    file_dict = {\n",
        "        1: \"https://raw.githubusercontent.com/rahcoderepo/NLP/refs/heads/main/DataSets/IMDB%20Dataset-GitHub-Ready-Less-Record.csv\",\n",
        "        2: \"https://raw.githubusercontent.com/rahcoderepo/NLP/refs/heads/main/DataSets/IMDB%20Dataset-GitHub-Ready-Less-Record-002.csv\",\n",
        "        3: \"https://raw.githubusercontent.com/rahcoderepo/NLP/refs/heads/main/DataSets/IMDB%20Dataset-GitHub-Ready-Less-Record-003.csv\"\n",
        "    }\n",
        "    main_data_field = \"review\" # This is the field name where the data to be trained on is found\n",
        "    senti_data_field = \"sentiment\" # This is the field name where the labels are found (Sentiment: Positive or Negative)\n",
        "\n",
        "df = combine_csv_files(file_dict)\n",
        "\n",
        "# Sample the loaded dataset\n",
        "df.sample(5)\n"
      ],
      "metadata": {
        "id": "4J34CuECMSdB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "71f7b9a8-5bac-4046-c523-405dbf02d009"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CSV file for key 1: https://raw.githubusercontent.com/rahcoderepo/NLP/refs/heads/main/DataSets/IMDB%20Dataset-GitHub-Ready-Less-Record.csv\n",
            "Loading CSV file for key 2: https://raw.githubusercontent.com/rahcoderepo/NLP/refs/heads/main/DataSets/IMDB%20Dataset-GitHub-Ready-Less-Record-002.csv\n",
            "Loading CSV file for key 3: https://raw.githubusercontent.com/rahcoderepo/NLP/refs/heads/main/DataSets/IMDB%20Dataset-GitHub-Ready-Less-Record-003.csv\n",
            "Combined DataFrame has 50000 records.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "20970  First let me say that Before Sunrise, like all...  positive\n",
              "44623  Alain Resnais directs three parallel stories t...  negative\n",
              "811    This movie is among my favorite foreign films,...  positive\n",
              "4003   A very courageous attempt to bring one of the ...  positive\n",
              "20505  This is one of the few episodes (if not the on...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07775a03-905e-48f4-996b-09fb0be10547\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20970</th>\n",
              "      <td>First let me say that Before Sunrise, like all...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44623</th>\n",
              "      <td>Alain Resnais directs three parallel stories t...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>811</th>\n",
              "      <td>This movie is among my favorite foreign films,...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4003</th>\n",
              "      <td>A very courageous attempt to bring one of the ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20505</th>\n",
              "      <td>This is one of the few episodes (if not the on...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07775a03-905e-48f4-996b-09fb0be10547')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07775a03-905e-48f4-996b-09fb0be10547 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07775a03-905e-48f4-996b-09fb0be10547');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-27c67604-1b3f-4b02-9fc6-fe923faadfe1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-27c67604-1b3f-4b02-9fc6-fe923faadfe1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-27c67604-1b3f-4b02-9fc6-fe923faadfe1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Alain Resnais directs three parallel stories that have to do with fantasy and imagination in the adult world. In one of them is a sort of Operatic bordello story where a rejected architect attempts to manipulate a group of people into throes of happiness--only his attempt misses it's only real target, the woman that he pines after. In the same unfinished ch\\u00e2teau he built, a group of teachers search for love in a more modern story, as one woman believes ineffably in the role of romance and the cynical anthropoligist tries to teach her a lesson by setting her up with the biggest jerk in the group. Meanwhile, a bunch of kids fantasize a George Melies-like adventure of a prince that saves a girl in distress from swamp creatures and then kills the evil king, bringing upon the kingdom of love. The two primary themes? Life is a fairy tale, and Life isn't a fairy tale.<br /><br />Which sounds better than the movie actually is. Resnais is the type of director where oftentimes the concept is good or bad, but the exposition is what matters; here, the concept is great but the movie is downright painful to watch. Horridly off-tune songs, bubbly characters without an ounce of dimension, backdrops of sickening pastel--instead of giving your inner child an ice cream cone, Resnais drowns it in a bucket of cake frosting. Add some French philosophy and you get a weird witches brew, one that doesn't bubble bubble toil and trouble, but just kinda sits wrong in your stomach until you want to regurgitate it.<br /><br />Resnais is a risk-taking director, and even in his worst you can see he's trying something that might not work with full clarity of action. In I Want to Go Home, he manages to pull past annoying characters and ditzy set-pieces by showing some real change and having a moment few moments of quiet to catch his breath. Here he submerges directly into a fantasy that doesn't really reflect fantasy, only its baby's room wallpaper reference. The biggest problem is that he somehow managed to make a movie more flamboyant than an 80s pop video, and more kitsch than Golden Era Hollywood musicals. The fantasies are beyond childish and naive, but the movie (with nudity and profanity) is definitely aimed for adults, a target he decidedly missed.<br /><br />However, he sticks closely to his theme and never backpedals. If anything, this movie is impressive simply because its unapologetic.<br /><br />--PolarisDiB\",\n          \"This is one of the few episodes (if not the only one) with an indisputable error in its storytelling. While handling the Ralphie situation Christopher states that he has heard about Pie-O-My's death in the fire accident. This is an important detail because in this context it is quite obvious that Christopher knows from the beginning that Tony is the one who must have killed Ralphie. There is however no way Chris could have heard about the accident. Who should have told him and when? By the time he is torn out of his delirium by Tony's call nobody else was informed. Tony knows that - which makes it even worse! Hearing Christopher talk about Pie- O-My's death could therefore only lead Tony to the conclusion that Chris himself has set the fire. Given the impressively elaborate writing process as told by the writers themselves on the DVD I really wonder none of them realized the problem there. The story just doesn't work that way. Unnecessary to add that I'm a huge fan of the Sopranos. Otherwise, I certainly wouldn't care.\",\n          \"This movie is among my favorite foreign films, some of the others are Amilee and My Life As a Dog. The similarities with those movies as with so many great foreign films, is that it takes a mundane slice of life and transforms it into a profound heartfelt lesson. <br /><br />In Japan, a man who is bored with his mundane life and the rut of his married life, sees a beautiful Japanese woman staring out the window of a dance studio. In the instant that it takes his train to pass, he is enthralled by her. But is it only by her beauty, by her faraway glance, or a connection that they will both discover that they share? <br /><br />Shall We Dance has memorable wonderful characters who have to deal with painful realities by transcending them through the world of dance. Breaking traditional moulds and stereo types of Japanese society, they risk all for happiness and find that joy is not too far away. It is one of those movies that is so magical and meaningful and, in itself, transcends the mundane by showing the true magic and miracle that life can be.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Inspecting the DataSet - Relevant Information\n",
        "\n",
        "#Dataset relevant information\n",
        "\n",
        "# Add columns to process these values\n",
        "# df['review_length'] = df['review'].apply(len)  # Add a column for review lengths\n",
        "# df['word_count'] = df['review'].apply(lambda x: len(x.split()))  # Add a column for word counts\n",
        "df['review_length'] = df[main_data_field].apply(len)  # Add a column for review lengths\n",
        "df['word_count'] = df[main_data_field].apply(lambda x: len(x.split()))  # Add a column for word counts\n",
        "\n",
        "\n",
        "# Find the record with the smallest len(main_data_field)\n",
        "min_len_index = df['review_length'].idxmin()   # Get the index of the record with the min length\n",
        "min_len_record = df.loc[min_len_index]         # Locate the record\n",
        "print(f\"Record index with the smallest len(review): {min_len_index}\")\n",
        "print(min_len_record)\n",
        "print()\n",
        "\n",
        "# Find the record with the largest len(main_data_field)\n",
        "max_len_index = df['review_length'].idxmax()   # Get the index of the record with the max length\n",
        "max_len_record = df.loc[max_len_index]         # Locate the record\n",
        "print(f\"Record index with the largest len(review): {max_len_index}\")\n",
        "print(max_len_record)\n",
        "print()\n",
        "\n",
        "# Find the record with the smallest number of words\n",
        "min_word_count_index = df['word_count'].idxmin()                # Get the index of the record with the min word count\n",
        "min_word_count_record = df.loc[min_word_count_index]            # Locate the record\n",
        "print(f\"\\nRecord index with the smallest number of words in review: {min_word_count_index}\")\n",
        "print(min_word_count_record)\n",
        "print()\n",
        "\n",
        "# Find the record with the largest number of words\n",
        "max_word_count_index = df['word_count'].idxmax()                # Get the index of the record with the max word count\n",
        "max_word_count_record = df.loc[max_word_count_index]            # Locate the record\n",
        "print(f\"\\nRecord index with the largest number of words in review: {max_word_count_index}\")\n",
        "print(max_word_count_record)\n",
        "print()\n",
        "\n",
        "# Combine the indices into a list\n",
        "indices = [min_len_index, min_word_count_index, max_len_index, max_word_count_index]\n",
        "# Display the selected records in the same format as df.sample()\n",
        "display(df.loc[indices])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "H0FMe5lRA_ey",
        "outputId": "5936e2e4-f25a-420f-ba4b-b390331dc44f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Record index with the smallest len(review): 27521\n",
            "review           Read the book, forget the movie!\n",
            "sentiment                                negative\n",
            "review_length                                  32\n",
            "word_count                                      6\n",
            "Name: 27521, dtype: object\n",
            "\n",
            "Record index with the largest len(review): 31481\n",
            "review           Match 1: Tag Team Table Match Bubba Ray and Sp...\n",
            "sentiment                                                 positive\n",
            "review_length                                                13704\n",
            "word_count                                                    2470\n",
            "Name: 31481, dtype: object\n",
            "\n",
            "\n",
            "Record index with the smallest number of words in review: 28920\n",
            "review           Primary plot!Primary direction!Poor interpreta...\n",
            "sentiment                                                 negative\n",
            "review_length                                                   51\n",
            "word_count                                                       4\n",
            "Name: 28920, dtype: object\n",
            "\n",
            "\n",
            "Record index with the largest number of words in review: 31481\n",
            "review           Match 1: Tag Team Table Match Bubba Ray and Sp...\n",
            "sentiment                                                 positive\n",
            "review_length                                                13704\n",
            "word_count                                                    2470\n",
            "Name: 31481, dtype: object\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  review sentiment  \\\n",
              "27521                   Read the book, forget the movie!  negative   \n",
              "28920  Primary plot!Primary direction!Poor interpreta...  negative   \n",
              "31481  Match 1: Tag Team Table Match Bubba Ray and Sp...  positive   \n",
              "31481  Match 1: Tag Team Table Match Bubba Ray and Sp...  positive   \n",
              "\n",
              "       review_length  word_count  \n",
              "27521             32           6  \n",
              "28920             51           4  \n",
              "31481          13704        2470  \n",
              "31481          13704        2470  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49d0c8b9-56da-4e05-a6ea-e53c8085a3e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_length</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27521</th>\n",
              "      <td>Read the book, forget the movie!</td>\n",
              "      <td>negative</td>\n",
              "      <td>32</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28920</th>\n",
              "      <td>Primary plot!Primary direction!Poor interpreta...</td>\n",
              "      <td>negative</td>\n",
              "      <td>51</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31481</th>\n",
              "      <td>Match 1: Tag Team Table Match Bubba Ray and Sp...</td>\n",
              "      <td>positive</td>\n",
              "      <td>13704</td>\n",
              "      <td>2470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31481</th>\n",
              "      <td>Match 1: Tag Team Table Match Bubba Ray and Sp...</td>\n",
              "      <td>positive</td>\n",
              "      <td>13704</td>\n",
              "      <td>2470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49d0c8b9-56da-4e05-a6ea-e53c8085a3e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-49d0c8b9-56da-4e05-a6ea-e53c8085a3e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-49d0c8b9-56da-4e05-a6ea-e53c8085a3e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f7c87a52-5a67-4479-933f-aec9a1b07179\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7c87a52-5a67-4479-933f-aec9a1b07179')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f7c87a52-5a67-4479-933f-aec9a1b07179 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Read the book, forget the movie!\",\n          \"Primary plot!Primary direction!Poor interpretation.\",\n          \"Match 1: Tag Team Table Match Bubba Ray and Spike Dudley vs Eddie Guerrero and Chris Benoit Bubba Ray and Spike Dudley started things off with a Tag Team Table Match against Eddie Guerrero and Chris Benoit. According to the rules of the match, both opponents have to go through tables in order to get the win. Benoit and Guerrero heated up early on by taking turns hammering first Spike and then Bubba Ray. A German suplex by Benoit to Bubba took the wind out of the Dudley brother. Spike tried to help his brother, but the referee restrained him while Benoit and Guerrero ganged up on him in the corner. With Benoit stomping away on Bubba, Guerrero set up a table outside. Spike dashed into the ring and somersaulted over the top rope onto Guerrero on the outside! After recovering and taking care of Spike, Guerrero slipped a table into the ring and helped the Wolverine set it up. The tandem then set up for a double superplex from the middle rope which would have put Bubba through the table, but Spike knocked the table over right before his brother came crashing down! Guerrero and Benoit propped another table in the corner and tried to Irish Whip Spike through it, but Bubba dashed in and blocked his brother. Bubba caught fire and lifted both opponents into back body drops! Bubba slammed Guerrero and Spike stomped on the Wolverine from off the top rope. Bubba held Benoit at bay for Spike to soar into the Wassup! headbutt! Shortly after, Benoit latched Spike in the Crossface, but the match continued even after Spike tapped out. Bubba came to his brother's rescue and managed to sprawl Benoit on a table. Bubba leapt from the middle rope, but Benoit moved and sent Bubba crashing through the wood! But because his opponents didn't force him through the table, Bubba was allowed to stay in the match. The first man was eliminated shortly after, though, as Spike put Eddie through a table with a Dudley Dawg from the ring apron to the outside! Benoit put Spike through a table moments later to even the score. Within seconds, Bubba nailed a Bubba Bomb that put Benoit through a table and gave the Dudleys the win! Winner: Bubba Ray and Spike Dudley<br /><br />Match 2: Cruiserweight Championship Jamie Noble vs Billy Kidman Billy Kidman challenged Jamie Noble, who brought Nidia with him to the ring, for the Cruiserweight Championship. Noble and Kidman locked up and tumbled over the ring, but raced back inside and grappled some more. When Kidman thwarted all Noble's moves, Noble fled outside the ring where Nidia gave him some encouragement. The fight spread outside the ring and Noble threw his girlfriend into the challenger. Kidman tossed Nidia aside but was taken down with a modified arm bar. Noble continued to attack Kidman's injured arm back in the ring. Kidman's injured harm hampered his offense, but he continued to battle hard. Noble tried to put Kidman away with a powerbomb but the challenger countered into a facebuster. Kidman went to finish things with a Shooting Star Press, but Noble broke up the attempt. Kidman went for the Shooting Star Press again, but this time Noble just rolled out of harm's way. Noble flipped Kidman into a power bomb soon after and got the pin to retain his WWE Cruiserweight Championship! Winner: Jamie Noble<br /><br />Match 3: European Championship William Regal vs Jeff Hardy William Regal took on Jeff Hardy next in an attempt to win back the European Championship. Jeff catapulted Regal over the top rope then took him down with a hurracanrana off the ring apron. Back in the ring, Jeff hit the Whisper in the wind to knock Regal for a loop. Jeff went for the Swanton Bomb, but Regal got his knees up to hit Jeff with a devastating shot. Jeff managed to surprise Regal with a quick rollup though and got the pin to keep the European Championship! Regal started bawling at seeing Hardy celebrate on his way back up the ramp. Winner: Jeff Hardy<br /><br />Match 4: Chris Jericho vs John Cena Chris Jericho had promised to end John Cena's career in their match at Vengeance, which came up next. Jericho tried to teach Cena a lesson as their match began by suplexing him to the mat. Jericho continued to knock Cena around the ring until his cockiness got the better of him. While on the top rope, Jericho began to showboat and allowed Cena to grab him for a superplex! Cena followed with a tilt-a-whirl slam but was taken down with a nasty dropkick to the gut. The rookie recovered and hit a belly to belly suplex but couldn't put Y2J away. Jericho launched into the Lionsault but Cena dodged the move. Jericho nailed a bulldog and then connected on the Lionsault, but did not go for the cover. He goaded Cena to his feet so he could put on the Walls of Jericho. Cena had other ideas, reversing the move into a pin attempt and getting the 1-2-3! Jericho went berserk after the match. Winner: John Cena<br /><br />Match 5: Intercontinental Championship RVD vs Brock Lesnar via disqualification The Next Big Thing and Mr. Pay-Per-View tangled with the Intercontinental Championship on the line. Brock grabbed the title from the ref and draped it over his shoulder momentarily while glaring at RVD. Van Dam 's quickness gave Brock fits early on. The big man rolled out of the ring and kicked the steel steps out of frustration. Brock pulled himself together and began to take charge. With Paul Heyman beaming at ringside, Brock slammed RVD to the hard floor outside the ring. From there, Brock began to overpower RVD, throwing him with ease over the top rope. RVD landed painfully on his back, then had to suffer from having his spine cracked against the steel ring steps. The fight returned to the ring with Brock squeezing RVD around the ribs. RVD broke away and soon after leveled Brock with a kick to the temple. RVD followed with the Rolling Thunder but Brock managed to kick out after a two-count. The fight looked like it might be over soon as RVD went for a Five-Star Frog Splash. Brock, though, hoisted Van Dam onto his shoulder and went for the F-5, but RVD whirled Brock into a DDT and followed with the Frog Splash! He went for the pin, but Heyman pulled the ref from the ring! The ref immediately called for a disqualification and soon traded blows with Heyman! After, RVD leapt onto Brock from the top rope and then threatened to hit the Van Terminator! Heyman grabbed RVD's leg and Brock picked up the champ and this time connected with the F-5 onto a steel chair! Winner: RVD<br /><br />Match 6: Booker T vs the Big Show Booker T faced the Big Show one-on-one next. Show withstood Booker T's kicks and punches and slapped Booker into the corner. After being thrown from the ring, Booker picked up a chair at ringside, but Big Show punched it back into Booker's face. Booker tried to get back into the game by choking Show with a camera cable at ringside. Booker smashed a TV monitor from the Spanish announcers' position into Show's skull, then delivered a scissors kick that put both men through the table! Booker crawled back into the ring and Big Show staggered in moments later. Show grabbed Booker's throat but was met by a low blow and a kick to the face. Booker climbed the top rope and nailed a somersaulting leg drop to get the pin! Winner: Booker T<br /><br />Announcement: Triple H entered the ring to a thunderous ovation as fans hoped to learn where The Game would end up competing. Before he could speak, Eric Bishoff stopped The Game to apologize for getting involved in his personal business. If Triple H signed with RAW, Bischoff promised his personal life would never come into play again. Bischoff said he's spent the past two years networking in Hollywood. He said everyone was looking for the next breakout WWE Superstar, and they were all talking about Triple H. Bischoff guaranteed that if Triple H signed with RAW, he'd be getting top opportunities coming his way. Stephanie McMahon stepped out to issue her own pitch. She said that because of her personal history with Triple H, the two of them know each other very well. She said the two of them were once unstoppable and they can be again. Bischoff cut her off and begged her to stop. Stephanie cited that Triple H once told her how Bischoff said Triple H had no talent and no charisma. Bischoff said he was young at the time and didn't know what he had, but he still has a lot more experience that Stephanie. The two continued to bicker back and forth, until Triple H stepped up with his microphone. The Game said it would be easy to say \\\"screw you\\\" to either one of them. Triple H went to shake Bischoff's hand, but pulled it away. He said he would rather go with the devil he knows, rather than the one he doesn't know. Before he could go any further, though, Shawn Michaels came out to shake things up. HBK said the last thing he wanted to do was cause any trouble. He didn't want to get involved, but he remembered pledging to bring Triple H to the nWo. HBK said there's nobody in the world that Triple H is better friends with. HBK told his friend to imagine the two back together again, making Bischoff's life a living hell. Triple H said that was a tempting offer. He then turned and hugged HBK, making official his switch to RAW! Triple H and HBK left, and Bischoff gloated over his victory. Bischoff said the difference between the two of them is that he's got testicles and she doesn't. Stephanie whacked Bischoff on the side of the head and left!<br /><br />Match 7: Tag Team Championship Match Christian and Lance Storm vs Hollywood Hogan and Edge The match started with loud \\\"USA\\\" chants and with Hogan shoving Christian through the ropes and out of the ring. The Canadians took over from there. But Edge scored a kick to Christian's head and planted a facebuster on Storm to get the tag to Hogan. Hogan began to Hulk up and soon caught Christian with a big boot and a leg drop! Storm broke up the count and Christian tossed Hogan from the ring where Storm superkicked the icon. Edge tagged in soon after and dropped both opponents. He speared both of them into the corner turnbuckles, but missed a spear on Strom and hit the ref hard instead. Edge nailed a DDT, but the ref was down and could not count. Test raced down and took down Hogan then leveled Edge with a boot. Storm tried to get the pin, but Edge kicked out after two. Riksihi sprinted in to fend off Test, allowing Edge to recover and spear Storm. Christian distracted the ref, though, and Y2J dashed in and clocked Edge with the Tag Team Championship! Storm rolled over and got the pinfall to win the title! Winners and New Tag Team Champions: Christian and Lance Storm<br /><br />Match 8: WWE Undisputed Championship Triple Threat Match. The Rock vs Kurt Angle and the Undertaker Three of WWE's most successful superstars lined up against each other in a Triple Threat Match with the Undisputed Championship hanging in the balance. Taker and The Rock got face to face with Kurt Angle begging for some attention off to the side. He got attention in the form of a beat down form the two other men. Soon after, Taker spilled out of the ring and The Rock brawled with Angle. Angle gave a series of suplexes that took down Rock, but the Great One countered with a DDT that managed a two-count. The fight continued outside the ring with Taker coming to life and clotheslining Angle and repeatedly smacking The Rock. Taker and Rock got into it back into the ring, and Taker dropped The Rock with a sidewalk slam to get a two-count. Rock rebounded, grabbed Taker by the throat and chokeslammed him! Angle broke up the pin attempt that likely would have given The Rock the title. The Rock retaliated by latching on the ankle lock to Kurt Angle. Angle reversed the move and Rock Bottomed the People's Champion. Soon after, The Rock disposed of Angle and hit the People's Elbow on the Undertaker. Angle tried to take advantage by disabling the Great One outside the ring and covering Taker, who kicked out after a two count. Outside the ring, Rock took a big swig from a nearby water bottle and spewed the liquid into Taker's face to blind the champion. Taker didn't stay disabled for long, and managed to overpower Rock and turn his attention to Angle. Taker landed a guillotine leg drop onto Angle, laying on the ring apron. The Rock picked himself up just in time to break up a pin attempt on Kurt Angle. Taker nailed Rock with a DDT and set him up for a chokeslam. ANgle tried sneaking up with a steel chair, but Taker caught on to that tomfoolery and smacked it out of his hands. The referee got caught in the ensuing fire and didn't see Angle knock Taker silly with a steel chair. Angle went to cover Taker as The Rock lay prone, but the Dead Man somehow got his shoulder up. Angle tried to pin Rock, but he too kicked out. The Rock got up and landed Angle in the sharpshooter! Angle looked like he was about to tap, but Taker kicked The Rock out of the submission hold. Taker picked Rock up and crashed him with the Last Ride. While the Dead Man covered him for the win, Angle raced in and picked Taker up in the ankle lock! Taker went delirious with pain, but managed to counter. He picked Angle up for the last ride, but Angle put on a triangle choke! It looked like Taker was about to pass out, but The Rock broke Angle's hold only to find himself caught in the ankle lock. Rock got out of the hold and watched Taker chokeslam Angle. Rocky hit the Rock Bottom, but Taker refused to go down and kicked out. Angle whirled Taker up into the Angle Slam but was Rock Bottomed by the Great One and pinned! Winner and New WWE Champion: The Rock<br /><br />~Finally there is a decent PPV! Lately the PPV weren't very good, but this one was a winner. I give this PPV a A-<br /><br />\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7888,\n        \"min\": 32,\n        \"max\": 13704,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          32,\n          51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1423,\n        \"min\": 4,\n        \"max\": 2470,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Text Cleaning and Tokenization - Define Functions\n",
        "# import re\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Function to clean text (pre-defined)\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabet characters\n",
        "    return text.lower().strip()\n",
        "\n",
        "# Removes specific words from a string - (Manual Definition to test the system)\n",
        "def remove_words_from_string(input_string, words_to_remove):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        input_string (str): The string to process.\n",
        "        words_to_remove (list): The list of words to remove.\n",
        "\n",
        "    Returns:\n",
        "        str: The string with specified words removed, or the original string if the list is empty.\n",
        "    \"\"\"\n",
        "    # If the list is empty, return the original string\n",
        "    if not words_to_remove:\n",
        "        return input_string\n",
        "\n",
        "    # Normalize case by making the list lowercase\n",
        "    words_to_remove_set = set(word.lower() for word in words_to_remove)\n",
        "\n",
        "    # Tokenize the input string and filter words\n",
        "    filtered_words = [\n",
        "        word for word in input_string.split()\n",
        "        if word.lower() not in words_to_remove_set\n",
        "    ]\n",
        "\n",
        "    # Reconstruct and return the filtered string\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "#     Prints a dictionary with a specified number of key-value pairs per line.\n",
        "def print_dic_multiline(dictionary, items_per_line):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        dictionary (dict): The dictionary to display.\n",
        "        items_per_line (int): Number of key-value pairs to display per line.\n",
        "    \"\"\"\n",
        "    # Convert dictionary items to a list of tuples\n",
        "    items = list(dictionary.items())\n",
        "\n",
        "    # Iterate through the dictionary in chunks\n",
        "    for i in range(0, len(items), items_per_line):\n",
        "        # Print a slice of the dictionary items\n",
        "        print(dict(items[i:i + items_per_line]))\n",
        "    print()  # Blank line for better readability\n",
        "\n",
        "#     Prints a nested list with a specified number of items per line.\n",
        "def print_nested_list_multiline(nested_list, items_per_line):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        nested_list (list of lists): The nested list to display.\n",
        "        items_per_line (int): Number of items to display per line.\n",
        "    \"\"\"\n",
        "    for i, inner_list in enumerate(nested_list):\n",
        "        print(f\"Inner list {i}:\")  # Label each inner list\n",
        "        for j in range(0, len(inner_list), items_per_line):\n",
        "            print(inner_list[j:j + items_per_line])  # Print chunks of the inner list\n",
        "        print()  # Blank line for better readability\n",
        "\n",
        "#     Prints the content of a string variable in multiple lines, with a specified number of characters per line.\n",
        "def print_multiline(data, chars_per_line):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        data (str): The string to display.\n",
        "        chars_per_line (int): The number of characters per line.\n",
        "    \"\"\"\n",
        "    for i in range(0, len(data), chars_per_line):\n",
        "        print(data[i:i + chars_per_line])\n",
        "\n"
      ],
      "metadata": {
        "id": "yKu13eeIN7N_"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Text Cleaning and Tokenization - Processing\n",
        "# Define the record index variable\n",
        "# Indexes for records with specific characteristics\n",
        "# 2097 - very small number of words in the review field\n",
        "# 14535 - very large number of words in the review field\n",
        "record_index = 0  # Set to 0 for all records, or an integer for a specific record\n",
        "\n",
        "#Define padding max number of words\n",
        "pad_nbr_words = 331\n",
        "\n",
        "#Define how many tuples per line to display when printing a dictionary\n",
        "tuples_per_line = 8\n",
        "\n",
        "#Defines how many items per line to display when printing a nested list\n",
        "items_per_line = 18\n",
        "\n",
        "#Defines number of charecters across when printing large string variables\n",
        "characters_across = 120\n",
        "\n",
        "#Defines number of key pairs in the ordered word_counts dict to display when tokenizing the entire data set\n",
        "word_counts_sliced_pairs = 100\n",
        "\n",
        "# List of words to remove manually (this is to test the system) - an empty list [] does nothing\n",
        "# Example: words_to_remove = ['the', 'i', 'more', 'bad', 'good']\n",
        "# words_to_remove = ['the','a','and']\n",
        "#\n",
        "# First Run\n",
        "if 'words_to_remove' not in globals():\n",
        "  words_to_remove = [] # Remove nothing\n",
        "\n",
        "#Comparison Variables\n",
        "original_data = ''\n",
        "original_data_length = 0\n",
        "cleaned_up_data = ''\n",
        "cleaned_up_data_length = 0\n",
        "\n",
        "\n",
        "# Record the start time and print the start message\n",
        "start_time = datetime.now()\n",
        "print(f\"Process started at: {start_time}\")\n",
        "print(\"==================================\")\n",
        "print()\n",
        "\n",
        "# Clean the reviews\n",
        "if record_index == 0:\n",
        "    # Process all records\n",
        "    df['review'] = df[main_data_field].apply(clean_text)\n",
        "\n",
        "    # Apply the function to all records in the 'review' column\n",
        "    df[main_data_field] = df[main_data_field].apply(lambda review: remove_words_from_string(review, words_to_remove))\n",
        "\n",
        "else:\n",
        "    # Process a specific record\n",
        "    original_data = str(df.loc[record_index, main_data_field]) # Hold Original Record Data\n",
        "    original_data_length = len(original_data) #Hold Original Data Length Value\n",
        "    df.loc[record_index, main_data_field] = clean_text(df.loc[record_index, main_data_field]) #Clen Up Single Record\n",
        "    cleaned_up_data = str(df.loc[record_index, main_data_field]) # Hold cleaned up record data\n",
        "    cleaned_up_data_length = len(cleaned_up_data) #Hold Cleaned Up Data Length Value\n",
        "    cleaned_up_data_word_count = len(cleaned_up_data.split())\n",
        "\n",
        "\n",
        "# Tokenization and padding\n",
        "if record_index == 0:\n",
        "\n",
        "    # Display time at this code line\n",
        "    right_now_time = datetime.now()\n",
        "    print(f\"Tokenization and padding Process started at: {datetime.now()}\")\n",
        "\n",
        "    # Tokenize and pad all records\n",
        "    tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
        "    tokenizer.fit_on_texts(df[main_data_field])\n",
        "\n",
        "    sorted_word_counts = sorted(tokenizer.word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    # Convert it back to a dictionary\n",
        "    sorted_word_counts_dict = dict(sorted_word_counts)\n",
        "    # Slice the first 15 key-value pairs\n",
        "    top_15_word_counts = dict(list(sorted_word_counts_dict.items())[:word_counts_sliced_pairs])  # Slicing first ? pairs\n",
        "    # Use the print_dic_multiline function for display\n",
        "    print_dic_multiline(top_15_word_counts, tuples_per_line)\n",
        "\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(df[main_data_field])\n",
        "    padded_sequences = pad_sequences(sequences, maxlen= pad_nbr_words)\n",
        "\n",
        "    # Display time at this code line\n",
        "    right_now_time = datetime.now()\n",
        "    print(f\"Tokenization and padding Process ended at: {right_now_time}\")\n",
        "\n",
        "    # Check the shape of the padded_sequences\n",
        "    print(f\"Shape of padded_sequences: {padded_sequences.shape}\")\n",
        "    print()\n",
        "\n",
        "else:\n",
        "    #Display Original vs Cleaned Up Data\n",
        "    print(f\"Processed record at index {record_index} - Original Record Data - Length = {original_data_length}\")\n",
        "    print_multiline(original_data,characters_across)\n",
        "    print()\n",
        "    print(f\"Processed record at index {record_index} - Cleaned Up Record Data - Length = {cleaned_up_data_length} - Difference = {cleaned_up_data_length - original_data_length}\")\n",
        "    print(f\"Number of words is: {cleaned_up_data_word_count}\")\n",
        "    print_multiline(cleaned_up_data,characters_across)\n",
        "    print()\n",
        "\n",
        "    # Tokenize and pad a single record\n",
        "    tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
        "    tokenizer.fit_on_texts([df.loc[record_index, main_data_field]])\n",
        "\n",
        "    # Display the tokenized word index dictionary\n",
        "    print(f\"Processed record at index {record_index} - Tokenized Word Index:\")\n",
        "    print_dic_multiline(tokenizer.word_index,tuples_per_line)\n",
        "\n",
        "    # Display the tokenized word count dictionary\n",
        "    print(f\"Processed record at index {record_index} - Tokenized Word Count:\")\n",
        "    # Display number of unique words in the corpus\n",
        "    num_unique_words = len(tokenizer.word_counts)\n",
        "    print(f\"Number of unique words in the corpus: {num_unique_words}\")\n",
        "    # Display the total word occurrences in the corpus\n",
        "    total_word_occurrences = sum(tokenizer.word_counts.values())\n",
        "    print(f\"Total word occurrences: {total_word_occurrences}\")\n",
        "    # Sort the word_counts dictionary by count in descending order\n",
        "    sorted_word_counts = sorted(tokenizer.word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    # Convert it back to a dictionary\n",
        "    sorted_word_counts_dict = dict(sorted_word_counts)\n",
        "    print_dic_multiline(sorted_word_counts_dict,tuples_per_line)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences([df.loc[record_index, main_data_field]])\n",
        "\n",
        "    print(f\"Processed record at index {record_index} - sequences:\")\n",
        "    print_nested_list_multiline(sequences, items_per_line)\n",
        "\n",
        "    padded_sequences = pad_sequences(sequences, maxlen= pad_nbr_words)\n",
        "\n",
        "# Print the result for clarity\n",
        "if record_index == 0:\n",
        "\n",
        "    print()\n",
        "    sequence_lengths = [len(seq) for seq in sequences]\n",
        "    print(f\"Max sequence length: {max(sequence_lengths)}\")\n",
        "    print(f\"Average sequence length: {sum(sequence_lengths)/len(sequence_lengths)}\")\n",
        "    print()\n",
        "\n",
        "    # Calculate percentiles\n",
        "    percentiles = np.percentile(sequence_lengths, [50, 75, 90, 95, 99])\n",
        "    print(f\"50th Percentile (Median): {percentiles[0]}\")\n",
        "    print(f\"75th Percentile: {percentiles[1]}\")\n",
        "    print(f\"90th Percentile: {percentiles[2]} - Recommended\")\n",
        "    print(f\"95th Percentile: {percentiles[3]}\")\n",
        "    print(f\"99th Percentile: {percentiles[4]}\")\n",
        "\n",
        "    print()\n",
        "    print(\"Processed all records.\")\n",
        "else:\n",
        "    print(f\"Processed record at index {record_index} - padded sequences:\")\n",
        "    print(padded_sequences)\n",
        "\n",
        "# Record the end time and print the end message\n",
        "print()\n",
        "print(\"==================================\")\n",
        "end_time = datetime.now()\n",
        "print(f\"Process ended at: {end_time}\")\n",
        "\n",
        "# Calculate and display the total time taken\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Cell process lasted: {elapsed_time}\")\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G-1pB4D2Pakw",
        "outputId": "77b5cc66-854c-4030-b21a-61af76a5328e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process started at: 2024-12-12 13:23:55.969869\n",
            "==================================\n",
            "\n",
            "Tokenization and padding Process started at: 2024-12-12 13:23:58.405371\n",
            "{'was': 95187, 'as': 90060, 'with': 86554, 'for': 86149, 'movie': 83578, 'but': 80337, 'film': 74514, 'on': 66316}\n",
            "{'not': 59512, 'you': 59169, 'are': 58161, 'his': 57202, 'have': 55020, 'be': 52715, 'he': 51783, 'one': 50392}\n",
            "{'its': 47902, 'at': 46172, 'all': 44517, 'by': 43933, 'an': 42658, 'they': 41346, 'who': 40122, 'from': 40083}\n",
            "{'like': 38834, 'so': 38571, 'or': 34908, 'just': 34683, 'her': 34213, 'about': 33848, 'has': 32883, 'out': 32714}\n",
            "{'if': 31948, 'some': 30643, 'what': 29442, 'there': 29166, 'good': 28502, 'more': 27637, 'very': 27489, 'when': 27401}\n",
            "{'even': 24285, 'up': 24230, 'no': 24208, 'my': 24061, 'would': 24001, 'she': 23796, 'time': 23299, 'only': 22997}\n",
            "{'which': 22987, 'really': 22900, 'their': 22656, 'see': 22437, 'were': 22171, 'story': 22062, 'had': 21967, 'can': 21825}\n",
            "{'me': 20788, 'than': 19167, 'much': 18897, 'we': 18792, 'well': 18463, 'been': 18257, 'get': 18184, 'will': 17973}\n",
            "{'into': 17794, 'other': 17776, 'great': 17723, 'do': 17715, 'bad': 17673, 'because': 17525, 'also': 17491, 'people': 17486}\n",
            "{'how': 17289, 'most': 17120, 'him': 16934, 'first': 16839, 'dont': 16635, 'movies': 15447, 'made': 15414, 'them': 15358}\n",
            "{'then': 15355, 'films': 15295, 'make': 15284, 'could': 15143, 'way': 15017, 'any': 14964, 'too': 14773, 'characters': 14658}\n",
            "{'after': 14406, 'think': 14190, 'watch': 13442, 'many': 13263, 'seen': 13097, 'being': 12989, 'two': 12927, 'character': 12915}\n",
            "{'never': 12833, 'love': 12549, 'acting': 12405, 'did': 12347}\n",
            "\n",
            "Tokenization and padding Process ended at: 2024-12-12 13:24:10.786610\n",
            "Shape of padded_sequences: (50000, 331)\n",
            "\n",
            "\n",
            "Max sequence length: 1906\n",
            "Average sequence length: 168.8828\n",
            "\n",
            "50th Percentile (Median): 126.0\n",
            "75th Percentile: 205.0\n",
            "90th Percentile: 331.0 - Recommended\n",
            "95th Percentile: 434.0\n",
            "99th Percentile: 667.0\n",
            "\n",
            "Processed all records.\n",
            "\n",
            "==================================\n",
            "Process ended at: 2024-12-12 13:24:10.804667\n",
            "Cell process lasted: 0:00:14.834798\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove Words (Optional)\n",
        "def process_word_pairs(word_dict):\n",
        "    \"\"\"\n",
        "    Process word pairs interactively.\n",
        "\n",
        "    Parameters:\n",
        "        word_dict (dict): Dictionary of word-frequency pairs.\n",
        "\n",
        "    Returns:\n",
        "        words_to_remove (list): List of words to include in the removal process.\n",
        "    \"\"\"\n",
        "    new_words_to_remove = []  # List to hold words to remove\n",
        "    pairs = list(word_dict.items())  # Convert dictionary to list of key-value pairs\n",
        "    total_pairs = len(pairs)\n",
        "\n",
        "    # Ask user how many pairs to process\n",
        "    while True:\n",
        "        try:\n",
        "            num_pairs = int(input(f\"How many word pairs would you like to process? (Max {total_pairs}): \"))\n",
        "            if 0 < num_pairs <= total_pairs:\n",
        "                break\n",
        "            else:\n",
        "                print(f\"Please enter a number between 1 and {total_pairs}.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a valid integer.\")\n",
        "\n",
        "    # Loop through the specified number of pairs\n",
        "    for i in range(num_pairs):\n",
        "        word, count = pairs[i]\n",
        "        response = input(f\"Pair {i+1}/{num_pairs} - Word: '{word}', Count: {count}. Include this word in the remove process? (Y/N): \").strip().upper()\n",
        "        if response == 'Y':\n",
        "            new_words_to_remove.append(word)\n",
        "        elif response == 'N':\n",
        "            continue\n",
        "        else:\n",
        "            print(\"Invalid response. Skipping to the next word.\")\n",
        "\n",
        "    print(\"\\nProcessing complete.\")\n",
        "    print(\"Existing Words selected for removal: words_to_remove = \", words_to_remove)\n",
        "    print(\"New Words selected for removal: new_words_to_remove = \", new_words_to_remove)\n",
        "    return new_words_to_remove\n",
        "\n",
        "# Call the function\n",
        "new_words_to_remove = process_word_pairs(top_15_word_counts)\n",
        "words_to_remove = words_to_remove + new_words_to_remove\n",
        "print()\n",
        "print(\"All Words selected for removal: words_to_remove = \", words_to_remove)\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0Z8CLeV_bdg",
        "outputId": "77793ff2-1dd5-45f1-cdb0-32ff9435b7e2"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How many word pairs would you like to process? (Max 100): 4\n",
            "Pair 1/4 - Word: 'was', Count: 95187. Include this word in the remove process? (Y/N): y\n",
            "Pair 2/4 - Word: 'as', Count: 90060. Include this word in the remove process? (Y/N): y\n",
            "Pair 3/4 - Word: 'with', Count: 86554. Include this word in the remove process? (Y/N): y\n",
            "Pair 4/4 - Word: 'for', Count: 86149. Include this word in the remove process? (Y/N): y\n",
            "\n",
            "Processing complete.\n",
            "Existing Words selected for removal: words_to_remove =  ['was', 'as']\n",
            "New Words selected for removal: new_words_to_remove =  ['was', 'as', 'with', 'for']\n",
            "\n",
            "All Words selected for removal: words_to_remove =  ['was', 'as', 'was', 'as', 'with', 'for']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Converting Labels to Numeric Format\n",
        "# Convert sentiment labels to binary\n",
        "# Modified to leave 0 and 1 as-is so that I can run it several times\n",
        "df[senti_data_field] = df[senti_data_field].apply(lambda x: x if x in [0, 1] else (1 if x == 'positive' else 0))\n",
        "\n",
        "# Splitting the data into features (X) and labels (y)\n",
        "X = padded_sequences\n",
        "y = df[senti_data_field].values\n",
        "\n",
        "#sample the data frame\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-UCQ0CJrze8k",
        "outputId": "b816fbf8-8ca6-492b-b9cf-bf8b01092920"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review  sentiment  \\\n",
              "31578  uggh hannabarbera s s what lousy unwatchable c...          0   \n",
              "40844  lossessa released english under many titles ee...          1   \n",
              "46644  was able hang for only first twenty minutes lo...          0   \n",
              "36001  havent seen ishtar but did have misfortune see...          0   \n",
              "20278  lets start off by saying jawani diwani just pa...          0   \n",
              "\n",
              "       review_length  word_count  \n",
              "31578           1315         219  \n",
              "40844           3800         643  \n",
              "46644           1132         180  \n",
              "36001            553         103  \n",
              "20278           1786         325  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d590699-cca4-460f-b14f-34cceadd0b70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_length</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31578</th>\n",
              "      <td>uggh hannabarbera s s what lousy unwatchable c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1315</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40844</th>\n",
              "      <td>lossessa released english under many titles ee...</td>\n",
              "      <td>1</td>\n",
              "      <td>3800</td>\n",
              "      <td>643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46644</th>\n",
              "      <td>was able hang for only first twenty minutes lo...</td>\n",
              "      <td>0</td>\n",
              "      <td>1132</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36001</th>\n",
              "      <td>havent seen ishtar but did have misfortune see...</td>\n",
              "      <td>0</td>\n",
              "      <td>553</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20278</th>\n",
              "      <td>lets start off by saying jawani diwani just pa...</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>325</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d590699-cca4-460f-b14f-34cceadd0b70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0d590699-cca4-460f-b14f-34cceadd0b70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0d590699-cca4-460f-b14f-34cceadd0b70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4499cb51-d84b-46b3-96f1-ba31ed627422\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4499cb51-d84b-46b3-96f1-ba31ed627422')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4499cb51-d84b-46b3-96f1-ba31ed627422 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"lossessa released english under many titles eeriest them certainly eerie midnight horror show one best italian ripoffs exorcist really appreciate film you should have sense humor lossessa at same time sleazy but naive pathetic sometimes even movingdanila stella carnacina an art student goes an old church see statue shes going restore its wooden statue christ demonic christ maybe already overcome by evil or fighting against or perhaps planning dark deeds face shows infinite torment statue dates from th century danila impressed by mastery shown by sculptor statue seems almost alive she lives with her parents her mother luisa lucretia love lives dissolute life doesnt care too much for keeping up appearances her father mario chris avram observes everything with disenchanted eyesthe wooden statue will soon assume human form ivan rassimov possess danila carnal spiritual sense an amazing scene poor danila from now on will suffer torments helldanila lovely stella carnacina was ravished violated possessed by devil now following his orders she will try seduce others aint she emulating her sleazy mother luisa lucretia love who feels great pleasure when her lover whips her with bunch roses there scene so ridiculous as be sublime moving when stella carnacina runs despair through narrow streets possessed by devil remember small italian town screaming her heart out luigi pistilli very good exorcist his performance as usual intense exorcism scenes particularlly final battle are very very amateurish but will only enhance fun andor emotion if youve really got sense humorstella carnacina beautiful looks fresh innocent thats factor adds your pleasure when shes naked but think film could have explored more her natural beauty lucretia love very good sleaze companion her nude scene with roses well other italian exorcist ripoffs would like recommend for you are malabimba very sleazy released uncut digitally restored evil eye malocchio exorcist was main source inspiration for evil eye but others films like for instance rosemarys baby should also be taken into account evil eye completely over top not sleazy but with plenty gorgeous italian spanish actresses youll be drooling all over film film ridiculous story doesnt make any sense but if you see right mood you might feel moved diabolical sect possession murders despair love investigation beautiful women all around wild ride if you liked evil eye see also ring darkness unombra nellombra film can be found alternative market search title imdb there are good reviews about itps lossessa has many different faces its exploitative but can also be serious moving its cheap cheesy sleazy but not much has an underlying moral message strange brew can sometimes be very funny we all already know lossessa an exorcist ripoff so why cant we see on its own terms yes mario gariazzo was trying earn fast buck but he was able get most out shoestring budget story well told film atmospheric overall actors are committed their roles see film with an open mind you may discover two or three new things\",\n          \"lets start off by saying jawani diwani just pathetic movie agree with last person who said missed joyride lol jokes were just terrible performances were average something went terribly wrong with film emraan totally deserved something better all celina jaitley did was expose hrishitta bhatt was ok emraan hashmi was ok toomann emraan hashmiis desperate guy who wants become famous therefore he uses radha pretends he loves her only because her father music director could help him become famous since father obeys everything his daughter says one day mann his friends go goa have some fun there he meets roma celina jaitley totally falls for her looks tries flirt with her bla bla bla then night roma cannot open door her room mann decides help her seeing he cannot as well roma goes ask for help while she gone mann able open door decides come inside sits on her bed bla bla bla roma comes they have one night stand however one night stand roma falls love with him morning they spot underworld don maheshwho sees all don loves roma couldnt stand what he saw he orders them get married being frightened mann obeys order merrys roma then their marriage news ends up newspaper mann later finds out he loves roma after they do music video together he now trapped between love fame bla bla blathe movie horrible songs sini ne sini ne fantastic remix version even better dil diwana also great title track also awesome guys avoid watching movie\",\n          \"was able hang for only first twenty minutes lowbudget movie most glaring absurdity was while american inmates north korean pow camp are all supposedly suffering from severe deprivation food medicine going without bathing shivering flimsy filthy parkas sleeping on bare floors lets not forget enduring torture they always manage sport impeccably coiffed hair with exception suitably austerelooking harry morgan as an army major casting acting are simply awful ronald regan cannot seem stick portraying single character instead creates rather schizophrenic amalgam past roles mostly caucasian cast portraying north korean camp officers might have been forgivable but when supposedly russian officers acting as advisors koreans strut around wearing rebadged nazi uniforms complete with jodhpurs jackboots obvious costumedepartment recycles from wwii flicks speaking with accents like general burkhalter from hogans heroes well thats just six kinds silly dont waste your time on one\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1245,\n        \"min\": 553,\n        \"max\": 3800,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3800,\n          1786\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 210,\n        \"min\": 103,\n        \"max\": 643,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          643,\n          325\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Explore X and y\n",
        "\n",
        "start_index = 28920  # Starting record (manual selection)\n",
        "show_this_many_records = 4  # Number of records to show (manual selection)\n",
        "end_index = start_index + show_this_many_records\n",
        "\n",
        "# Display records 20 to 24 for X (padded_sequences) with record numbers on separate lines\n",
        "print(f\"Records {start_index} to {end_index - 1} of X (padded_sequences):\")\n",
        "for i, record in enumerate(X[start_index:end_index], start=start_index):\n",
        "    print(f\"Record {i}:\")  # Record number on its own line\n",
        "    print(record)         # Content on the next line\n",
        "    print() # extra line for reading clarity\n",
        "\n",
        "\n",
        "# Display records 20 to 24 for y (sentiment values) with record numbers\n",
        "print(f\"\\nRecords {start_index} to {end_index - 1} of y (sentiment):\")\n",
        "for i, sentiment in enumerate(y[start_index:end_index], start=start_index):\n",
        "    print(f\"Record {i}: {sentiment}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2KyEeF7pZIB",
        "outputId": "792eb3f6-4a11-4afa-f672-c5872c0dd4fa"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Records 28920 to 28923 of X (padded_sequences):\n",
            "Record 28920:\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0 3962    1    1 2832]\n",
            "\n",
            "Record 28921:\n",
            "[   8 8808 6135  767  877   17 2085   87  133  768  180 1837    1 6816\n",
            "   77    8 5197 8421   14  398 1307 1235 1990    7 1057   54   40  856\n",
            "  180   83   54 7617   19  225 2985 1074 1324    1  505   25  141  244\n",
            " 2300  236 1350    1    2   77  179    1    8  329 9333    4 1258 1569\n",
            " 1656   21 3765 3843  188   23   88 2376 5077    5 1061 1074    7   48\n",
            "    3  203    3  101 9333  187  190    1    5  275 8172  767    3  749\n",
            "  373 5286 4422   28 3423   41  192   19   45  655  374 1073  182   45\n",
            " 1001   56  200  276  424    2  347 5226    1  277    1   24  785   22\n",
            " 6146   66 5788 9336 1821 1368   13  556    3   47    2    9 1771  384\n",
            " 1481   41 7991 4138  814  207 2527 2323  835   98 3539   87  133  768\n",
            "   98  235  503   19   20  872   87   89    3  233   81   54   40   96\n",
            " 4022  231 1859   42  193    1    1  170   15    1   13  227  157   48\n",
            "   16  690    9  270   16  264  992 1052   16  128   15    3   37   44\n",
            "  209 1039    5   77  530    8    3    5 1569  102   69  352 2392   19\n",
            "   40  206   61   46   64  573  260  765  608  171 1365    7  289   61\n",
            "   64 8322  432  283 8322  120    4 3350  304 2318    1 9869  123   37\n",
            "  417 1918  185 7626  135    1   25 1315  409  446   64  301  148   26\n",
            " 6179    9  976  899 5873   11 3882  773    1  451   72 1422 2964    3\n",
            "  333   48  255  430   33  678  125   67  333    8    2 1253  310   43\n",
            "    4  117  190  588 6279 9726   50   80   44  268   28 2689   87 1217\n",
            "   23   42 3361  204    1 1762 9610   25 1569 3423   50   29  546   88\n",
            "  646   33  262   15 1129  266   20 1550  351  128   29  803   31  244\n",
            "   84 1565 9333   83    3   23   14  230   84   17  474   27  215  233\n",
            "   17   32   63    3  653    3   22  380 1570]\n",
            "\n",
            "Record 28922:\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0   14   49   94    1   19   22 5875  741\n",
            "    1  358   26  192 2995  202 1853  568    1    5 2233  372    1    4\n",
            "   20 3828    1 1225 1222  628  113   30  496 5567   81  131   66 2562\n",
            "   82 1464   81  131    9 2926  119  177    1    1  789    5  377 1358\n",
            " 2340  305 1038   26 2340   68    1 7558    1]\n",
            "\n",
            "Record 28923:\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0 1297 6344  399    3  388   24   11   57 1885    1 2176  133  108\n",
            "    8   50  819   10   26    7  997   43 3598   10    6  421   33 1367\n",
            "  143   18   29   32  179  516   61   20   26 1297 6344  191   36  441\n",
            " 1063   46  492   53   25   76    7   11  106   36  400    6 6344  399\n",
            "    3 2176 3132 9024  350  806 2310   78   51   26   76   17 2436   76\n",
            "   13 2310 1998  174   53   13  225  125   37   16  251    1  702    5\n",
            "  243   41   16  194  131   13  311   16  642   33   13  625    1   21\n",
            "    1 3683 4210    1   21 6603    1  133  108   19  202  235  211 1331\n",
            "   12 3132  225   51  226   73   24   69    1  281  278 1771 1510  281\n",
            "   69  710   67  225  167   46  525  755   78  106   87  225   24   26\n",
            " 5634   58   25  695 3596   43    1  133  108]\n",
            "\n",
            "\n",
            "Records 28920 to 28923 of y (sentiment):\n",
            "Record 28920: 0\n",
            "Record 28921: 0\n",
            "Record 28922: 1\n",
            "Record 28923: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 002 - Code Block (Optional)\n",
        "\n",
        "        Cells:\n",
        "        1 - Define Functions - Reorder X and y based on the specified order field in the DataFrame.\n",
        "        2 - Process - Reorder X and y based on the specified order field in the DataFrame.\n",
        "\n",
        "Notes:\n",
        "RAH word count - padded sequenced \"fixed\" split, this is done to test model training on either lower word count or higher word count by ordering the data in either ascending or descending order according to the word count and then preventing the randomness from affecting the train_test_split process"
      ],
      "metadata": {
        "id": "rx8qOic1kGCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Functions - Reorder X and y based on the specified order field in the DataFrame.\n",
        "def reorder_X_y(df, order_field, ascending, X, y):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The DataFrame reference.\n",
        "        order_field (str): The column name used for ordering.\n",
        "        ascending (bool): The sort order (True for ascending, False for descending).\n",
        "        X (list/array/DataFrame): The current features.\n",
        "        y (list/array/Series): The current labels.\n",
        "\n",
        "    Returns:\n",
        "        tuple: X_new, y_new (reordered features and labels of the same type as input).\n",
        "    \"\"\"\n",
        "    # Step 1: Verify the order field exists and contains integer values\n",
        "    if order_field not in df.columns or not pd.api.types.is_integer_dtype(df[order_field]):\n",
        "        print(\"Invalid order field. Returning the original X and y.\")\n",
        "        return X, y  # Return unchanged if the field is invalid\n",
        "\n",
        "    # Step 2: Reorder the DataFrame based on the order_field and sort order\n",
        "    df_sorted = df.sort_values(by=order_field, ascending=ascending).reset_index(drop=True)\n",
        "\n",
        "    # Step 3: Determine the type of X and y, and reorder accordingly\n",
        "    X_new = [X[i] for i in df_sorted.index]  # General default behavior\n",
        "    y_new = [y[i] for i in df_sorted.index]\n",
        "\n",
        "    # Preserve the type of X\n",
        "    if isinstance(X, np.ndarray):\n",
        "        X_new = np.array(X_new)\n",
        "    elif isinstance(X, pd.DataFrame):\n",
        "        X_new = pd.DataFrame(X_new, columns=X.columns if hasattr(X, \"columns\") else None)\n",
        "\n",
        "    # Preserve the type of y\n",
        "    if isinstance(y, np.ndarray):\n",
        "        y_new = np.array(y_new)\n",
        "    elif isinstance(y, pd.Series):\n",
        "        y_new = pd.Series(y_new, name=y.name if hasattr(y, \"name\") else None)\n",
        "\n",
        "    return X_new, y_new  # Return the reordered objects with the original types"
      ],
      "metadata": {
        "id": "AYOHi9CUpkgA"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Process - Reorder X and y based on the specified order field in the DataFrame.\n",
        "df_order_field = \"word_count\"\n",
        "reorder_X_y_sort_ascending = False\n",
        "X_new, y_new = reorder_X_y(df, df_order_field , reorder_X_y_sort_ascending , X, y)\n",
        "\n",
        "# replace original X and y with newly reordered X_new and y_new\n",
        "X = X_new\n",
        "y = y_new"
      ],
      "metadata": {
        "id": "cIpO7D99DXoi"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 003 - Code Block\n",
        "\n",
        "        Cells:\n",
        "        1 - Splitting the Data into Training and Testing Sets (sklearn.model_selection.train_test_split)\n",
        "        2 - Display Train/Test Arrays Shapes\n",
        "        3- Building the Neural Network with TensorFlow\n",
        "        4 - Visualizing Model Performance\n",
        "        5 - Evaluating the Model\n",
        "        \n"
      ],
      "metadata": {
        "id": "1VcLXLHxk6mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Splitting the Data into Training and Testing Sets (sklearn.model_selection.train_test_split)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "my_test_size = 0.2\n",
        "my_random_state = 42 # Becomes irrelevant when shuffle=False\n",
        "my_shuffle = True # Set to False for a deterministic split with 0 randomness / training data contains top portion and test data the bottom portion\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=my_test_size, shuffle=my_shuffle, random_state=my_random_state)"
      ],
      "metadata": {
        "id": "GTRD7qQk1aFq"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Display Train/Test Arrays Shapes\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "print(\"First record in X_train:\")\n",
        "print(X_train[0])  # First record in X_train\n",
        "\n",
        "print(\"\\nSecond record in X_test:\")\n",
        "print(X_test[1])  # Second record in X_test\n",
        "\n",
        "print(\"\\nFirst label in y_train:\", y_train[0])\n",
        "print(\"First label in y_test:\", y_test[0])\n",
        "\n",
        "print(\"\\nSecond label in y_train:\", y_train[1])\n",
        "print(\"Second label in y_test:\", y_test[1])\n",
        "\n",
        "print(\"\\nSummary of X_train:\")\n",
        "print(\"Max value:\", np.max(X_train))\n",
        "print(\"Min value:\", np.min(X_train))\n",
        "print(\"Mean value:\", np.mean(X_train))\n",
        "\n",
        "print(\"\\nSummary of y_train:\")\n",
        "print(\"Unique labels:\", np.unique(y_train, return_counts=True))\n",
        "\n",
        "# Convert a subset of X_train to a DataFrame for inspection\n",
        "X_train_df = pd.DataFrame(X_train[:5])\n",
        "X_train_df.sample(5)\n",
        "# print(\"\\nFirst 5 records in X_train as DataFrame:\")\n",
        "# print(X_train_df)\n",
        "\n",
        "# y_train_df = pd.DataFrame(y_train, columns=[\"Sentiment\"])\n",
        "# print(\"\\nFirst 5 labels in y_train as DataFrame:\")\n",
        "# print(y_train_df.head())\n",
        "\n",
        "# # Visualize label distribution\n",
        "# plt.hist(y_train, bins=2, edgecolor='black')\n",
        "# plt.title(\"Distribution of Labels in y_train\")\n",
        "# plt.xlabel(\"Label\")\n",
        "# plt.ylabel(\"Frequency\")\n",
        "# plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Siwr4BZgLSBQ",
        "outputId": "e0b7aeb8-9a70-4ef8-a57b-25e25f84fbbd"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (40000, 331)\n",
            "X_test shape: (10000, 331)\n",
            "y_train shape: (40000,)\n",
            "y_test shape: (10000,)\n",
            "First record in X_train:\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0  165   36  743 2060  503  284   93\n",
            " 1793 1960 4371 6480  784 5160    1  217 5986   72  849   43   41   11\n",
            "   91 4286   89   24   14   27  104 1117 2255 1130  437   36  522   81\n",
            "   23   12   29  917  415    1    5  163 2969   13    1 4587    9 2897\n",
            "   32   63  213   60  112   67 3079  180    9  228    1  198 4823  132\n",
            "   10   51   17    5    1   70  342  284    8    7  198   15  283    1\n",
            "    1    3 8299    1  105  426    1    1    3 1542    1  625   54  393\n",
            "  365   78  106   36  100  362   23    1   25    7   34    2   81  453\n",
            " 6522    5  360    1 1922    1   49    1    1  443  205  962 4177  169\n",
            " 2931  675  612   62  224   98  801   25  162   19  206  165  405  353\n",
            "   48 3545  256    1 1644  182    1    1  704 1896 1104 2987    1 3681\n",
            " 1839    1  140  132  211  196  308  132 1034    4   75  117 2524 8660\n",
            "    7  137 9486   87 3880  284    6  986   25    1  497    1  236   61\n",
            "   64   93   93  664 9868   50    1   74   54 1262  220  117   12 4025\n",
            "   21  124    1  197 1077    3 3622 5332   21    1 2302    1    1  423\n",
            "    3  607  686 2894 1187    1   61 3424  163 1409 1171 1576  839 1189\n",
            "  295  129 2455  392    1  261 3577  959   15   29    1    3 1319  194\n",
            "   52    1   37   19  206   17  179 1462 1073    7 4439    1    1   71\n",
            "  219   56  334   58 4590 3553    5   18   10  178 8172    1 1765   11\n",
            "   14  141  183  159  103 1451  442   63  213  317 3175   24   12   39\n",
            "   59 1834 5655    3 1281    8 3474 2018    4   49 2323  443  515  156\n",
            " 2537    1    1  555   25 3897  198  332 3798]\n",
            "\n",
            "Second record in X_test:\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0   10   93\n",
            "  674  245 1265  166    3   93  256 2628  441   26 9186    1  106 7220\n",
            "  139    1  180  895  624    3   93  256 2919    3   11   57   91   29\n",
            " 6136  228 2610   32  761   57   15  235  199  157   67  107    9  228\n",
            "   97 2549  459   85   15   25   22 2007 1888 1342  230  151  380   32\n",
            " 1080  176 1197   46  183   42    1    1  497    5   13  280    1 8699\n",
            "    1 2615   48 1998  276    1    1    1 5773   25   20  115 5177    3\n",
            " 4476   12 2061  246 2506  399 1487 2846 7322 2039    1  124 3687 4530\n",
            "   46   15  819  148   46   15  454  364   43 7216    5  190    7  123\n",
            "  102 9186   51  249   66   18  186    1 2712  102   20  366   14 1157\n",
            "  247 1104  325 2105 2305    4 2293 1652    1 1473   23 1992   33  973\n",
            "  168  904  743    1   81  115  248 2367   23 1784  364 1074  659  750\n",
            "   38 2391 1761   97 5328    4 2506 7007  157  380    4  918  879 2403\n",
            "  363   12 3076  722   97 3578  717  204 2389 2065    5   22  531  989\n",
            " 1516  767  491    3    1   12    1 1855   93  740    9   93   93 1200\n",
            "  569   53 1862 4512 2654   29   56  364    1   90   53   34    1   46\n",
            "  109   64  239   90  292   81   20    9  674    2 6482   53   81 1231\n",
            "    9  259   14  933    2   49  135  743   58 6518 1743   56   69  530\n",
            "  302 6262 1431    1    1    2   49  135   64   58  129  130  531  190\n",
            "    1  616 5125   92 1862   53   36    1 9013]\n",
            "\n",
            "First label in y_train: 0\n",
            "First label in y_test: 1\n",
            "\n",
            "Second label in y_train: 0\n",
            "Second label in y_test: 1\n",
            "\n",
            "Summary of X_train:\n",
            "Max value: 9999\n",
            "Min value: 0\n",
            "Mean value: 430.76344667673715\n",
            "\n",
            "Summary of y_train:\n",
            "Unique labels: (array([0, 1]), array([20039, 19961]))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0    1    2    3    4    5    6    7    8    9    ...   321   322   323  \\\n",
              "3    0    0    0    0    0    0    0    0    0    0  ...     4    50  3100   \n",
              "4    0    0    0    0    0    0    0    0    0    0  ...    61   224   330   \n",
              "2    0    0    0    0    0    0    0    0    0    0  ...    16     1     4   \n",
              "0    0    0    0    0    0    0    0    0    0    0  ...   156  2537     1   \n",
              "1    0    0    0    0    0    0    0    0    0    0  ...  1034     6    85   \n",
              "\n",
              "    324  325   326   327  328  329   330  \n",
              "3  3462   56    21    82  398  309  3417  \n",
              "4    35  154   537  8361    6  240     1  \n",
              "2  1442    1   394    76  290  724    55  \n",
              "0     1  555    25  3897  198  332  3798  \n",
              "1    14   63  1681     7  191   78    92  \n",
              "\n",
              "[5 rows x 331 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bb6cb59-ea7d-4ac4-b230-4aa3243ba66a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>321</th>\n",
              "      <th>322</th>\n",
              "      <th>323</th>\n",
              "      <th>324</th>\n",
              "      <th>325</th>\n",
              "      <th>326</th>\n",
              "      <th>327</th>\n",
              "      <th>328</th>\n",
              "      <th>329</th>\n",
              "      <th>330</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>3100</td>\n",
              "      <td>3462</td>\n",
              "      <td>56</td>\n",
              "      <td>21</td>\n",
              "      <td>82</td>\n",
              "      <td>398</td>\n",
              "      <td>309</td>\n",
              "      <td>3417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>61</td>\n",
              "      <td>224</td>\n",
              "      <td>330</td>\n",
              "      <td>35</td>\n",
              "      <td>154</td>\n",
              "      <td>537</td>\n",
              "      <td>8361</td>\n",
              "      <td>6</td>\n",
              "      <td>240</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1442</td>\n",
              "      <td>1</td>\n",
              "      <td>394</td>\n",
              "      <td>76</td>\n",
              "      <td>290</td>\n",
              "      <td>724</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>156</td>\n",
              "      <td>2537</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>555</td>\n",
              "      <td>25</td>\n",
              "      <td>3897</td>\n",
              "      <td>198</td>\n",
              "      <td>332</td>\n",
              "      <td>3798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1034</td>\n",
              "      <td>6</td>\n",
              "      <td>85</td>\n",
              "      <td>14</td>\n",
              "      <td>63</td>\n",
              "      <td>1681</td>\n",
              "      <td>7</td>\n",
              "      <td>191</td>\n",
              "      <td>78</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 331 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bb6cb59-ea7d-4ac4-b230-4aa3243ba66a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6bb6cb59-ea7d-4ac4-b230-4aa3243ba66a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6bb6cb59-ea7d-4ac4-b230-4aa3243ba66a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fc849614-87fc-485c-b2b9-54b1f106de66\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc849614-87fc-485c-b2b9-54b1f106de66')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fc849614-87fc-485c-b2b9-54b1f106de66 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Building the Neural Network with TensorFlow\n",
        "# import tensorflow as tf # (Already Loaded)\n",
        "\n",
        "#  tf.keras.layers.Embedding(10000, 16, input_length=200),\n",
        "#  \"input_length\" deprecated, Keras can automatically infer the input length from the shape of the training data\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(10000, 16),\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Record the start time and print the start message\n",
        "start_time = datetime.now()\n",
        "print(f\"Process started at: {start_time}\")\n",
        "print(\"==================================\")\n",
        "print()\n",
        "\n",
        "# Default is epochs = 10 / Use epochs = 1 to test that the code works\n",
        "my_number_of_epochs = 2\n",
        "my_validation_split = 0.1 # Independent from test_size in train_test_split\n",
        "my_batch_size = 64\n",
        "history = model.fit(X_train, y_train, epochs=my_number_of_epochs, validation_split=my_validation_split, batch_size=my_batch_size)\n",
        "\n",
        "# Record the end time and print the end message\n",
        "print()\n",
        "print(\"==================================\")\n",
        "end_time = datetime.now()\n",
        "print(f\"Process ended at: {end_time}\")\n",
        "\n",
        "# Calculate and display the total time taken\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Cell process lasted: {elapsed_time}\")\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyCmn4MY2YZJ",
        "outputId": "925fbb88-d2c0-47bc-b42d-813aa7212671"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process started at: 2024-12-12 13:37:43.443982\n",
            "==================================\n",
            "\n",
            "Epoch 1/2\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.7146 - loss: 0.5284 - val_accuracy: 0.8575 - val_loss: 0.3368\n",
            "Epoch 2/2\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.8980 - loss: 0.2629 - val_accuracy: 0.8773 - val_loss: 0.3170\n",
            "\n",
            "==================================\n",
            "Process ended at: 2024-12-12 13:38:26.733980\n",
            "Cell process lasted: 0:00:43.289998\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualizing Model Performance\n",
        "# import matplotlib.pyplot as plt # (Already Loaded)\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "-aINy_pS9Wyb",
        "outputId": "45eeee73-53dd-4e72-ca9a-3055ec6164ed",
        "cellView": "form"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Evaluating the Model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "# print(f'Test Accuracy: {test_accuracy:.2f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSuQk3senYXC",
        "outputId": "abf83f7d-796d-4ff5-fe10-a17cf252232e",
        "cellView": "form"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8846 - loss: 0.2895\n",
            "Test Accuracy: 0.8840, Test Loss: 0.2943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 004 - Code Block\n",
        "\n",
        "        Cells:\n",
        "        1 - Making Predictions\n",
        "        "
      ],
      "metadata": {
        "id": "hgBqiKO2lD9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Making Predictions\n",
        "sample_reviews = [\n",
        "    \"I absolutely loved this movie! The plot was thrilling and the characters were so well developed.\",\n",
        "    \"The film was a disaster. Poor acting and a predictable storyline.\",\n",
        "    \"Mediocre movie plot, but the acting was great\",\n",
        "    \"Great movie plot, but the acting was mediocre\",\n",
        "    \"I like the first half and dislike  the second half\",\n",
        "    \"the best movie ever\",\n",
        "    \"the worst movie ever\",\n",
        "    \"This is the worst movie I've ever seen, in my opinion\",\n",
        "    \"I laughed the entire movie\",\n",
        "    \"I laughed the entire movie, supper funny film\",\n",
        "    \"I laughed the entire movie, supper funny film, my wife could not believe I was so happy\",\n",
        "    \"My wife fell asleep after 5 minutes\",\n",
        "    \"I couldn't take my eyes of the screen, plot was very intriguing\",\n",
        "    \"I couldn't take my eyes of the screen, plot was very intriguing, great cast selection\",\n",
        "    \"I couldn't take my eyes of the screen, plot was very intriguing, great cast selection, director did a great job\",\n",
        "    \"I couldn't take my eyes of the screen, plot was very intriguing, I liked the actors very much\",\n",
        "    \"After this film I am never coming to the movies again ever\",\n",
        "    \"too long, plot and acting just ok, not my type of movie\",\n",
        "    \"I don't know, I don't know, I just really don't know\"\n",
        "]\n",
        "\n",
        "#Calibrating sample review - use to adjust the prob split from Negative to Positive Outcome\n",
        "#Comment it to run the model on the real sample reviews values shown above\n",
        "# sample_reviews = [\n",
        "#     \"the best movie ever\",\n",
        "#     \"the worst movie ever\",\n",
        "#     \"I have nothing to say\",\n",
        "#     \"I have a lot to say\",\n",
        "#     \"I loved the first half and hated the second half\",\n",
        "#     \"I hated the first half and loved the second half\"\n",
        "# ]\n",
        "\n",
        "pos_neg_split = 0.42\n",
        "\n",
        "sample_sequences = tokenizer.texts_to_sequences(sample_reviews)\n",
        "sample_padded = pad_sequences(sample_sequences, maxlen=pad_nbr_words)\n",
        "\n",
        "predictions = model.predict(sample_padded)\n",
        "\n",
        "# print('Original Display Format')\n",
        "# print([\"Positive\" if prob > 0.4 else \"Negative\" for prob in predictions])\n",
        "# print()\n",
        "\n",
        "print()\n",
        "print('Process Details:')\n",
        "print('================')\n",
        "print(f\"Padding Recommendation: {percentiles[2]} - 90th Percentile\")\n",
        "print(f'Sequence Padding: {pad_nbr_words}')\n",
        "print(f'Words to remove: {words_to_remove}')\n",
        "print()\n",
        "print('Train, Test, Split Info')\n",
        "print('=======================')\n",
        "print(f'Test Split Size: {my_test_size}')\n",
        "print(f'Split Shuffle: {my_shuffle}')\n",
        "print()\n",
        "\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "print()\n",
        "print('Test Loss and Accuracy')\n",
        "print(f'Test Loss: {test_loss:.2f}, Test Accuracy: {test_accuracy:.2f}')\n",
        "print()\n",
        "print(f'Positive/Negative Split = {pos_neg_split}')\n",
        "print()\n",
        "# Combine predictions with reviews prob > 0.5 default\n",
        "result = [\n",
        "    (prob[0], f\"{'P' if prob > pos_neg_split else 'N'}-{prob[0]:.2f}: {review}\")\n",
        "    for review, prob in zip(sample_reviews, predictions)\n",
        "]\n",
        "\n",
        "# Sort results by probability in ascending order\n",
        "result_sorted = sorted(result, key=lambda x: x[0])\n",
        "\n",
        "# Print each result on a separate line\n",
        "for _, item in result_sorted:\n",
        "    print(item)\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd5itjpUnmSJ",
        "outputId": "f59fecf2-4808-466a-b3f5-6e90b6f5d1a5"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\n",
            "Process Details:\n",
            "================\n",
            "Padding Recommendation: 331.0 - 90th Percentile\n",
            "Sequence Padding: 331\n",
            "Words to remove: ['and', 'of', 'in', 'it', 'i', 'this', 'that']\n",
            "\n",
            "Train, Test, Split Info\n",
            "=======================\n",
            "Test Split Size: 0.2\n",
            "Split Shuffle: True\n",
            "\n",
            "X_train shape: (40000, 331)\n",
            "X_test shape: (10000, 331)\n",
            "y_train shape: (40000,)\n",
            "y_test shape: (10000,)\n",
            "\n",
            "Test Loss and Accuracy\n",
            "Test Loss: 0.29, Test Accuracy: 0.88\n",
            "\n",
            "Positive/Negative Split = 0.42\n",
            "\n",
            "N-0.02: The film was a disaster. Poor acting and a predictable storyline.\n",
            "N-0.03: This is the worst movie I've ever seen, in my opinion\n",
            "N-0.05: too long, plot and acting just ok, not my type of movie\n",
            "N-0.13: Mediocre movie plot, but the acting was great\n",
            "N-0.15: My wife fell asleep after 5 minutes\n",
            "N-0.18: I like the first half and dislike  the second half\n",
            "N-0.21: Great movie plot, but the acting was mediocre\n",
            "N-0.24: I don't know, I don't know, I just really don't know\n",
            "N-0.32: After this film I am never coming to the movies again ever\n",
            "N-0.37: the worst movie ever\n",
            "N-0.41: I couldn't take my eyes of the screen, plot was very intriguing\n",
            "P-0.54: I laughed the entire movie, supper funny film, my wife could not believe I was so happy\n",
            "P-0.61: I laughed the entire movie, supper funny film\n",
            "P-0.68: I couldn't take my eyes of the screen, plot was very intriguing, I liked the actors very much\n",
            "P-0.68: I absolutely loved this movie! The plot was thrilling and the characters were so well developed.\n",
            "P-0.70: I couldn't take my eyes of the screen, plot was very intriguing, great cast selection\n",
            "P-0.80: I laughed the entire movie\n",
            "P-0.82: I couldn't take my eyes of the screen, plot was very intriguing, great cast selection, director did a great job\n",
            "P-0.93: the best movie ever\n",
            "\n"
          ]
        }
      ]
    }
  ]
}